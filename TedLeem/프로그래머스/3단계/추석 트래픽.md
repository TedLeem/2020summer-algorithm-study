# 문제
이번 추석에도 시스템 장애가 없는 명절을 보내고 싶은 어피치는 서버를 증설해야 할지 고민이다.    
장애 대비용 서버 증설 여부를 결정하기 위해 작년 추석 기간인 9월 15일 로그 데이터를 분석한 후 초당 최대 처리량을 계산해보기로 했다.   
초당 최대 처리량은 요청의 응답 완료 여부에 관계없이 임의 시간부터 1초(=1,000밀리초)간 처리하는 요청의 최대 개수를 의미한다.   
https://programmers.co.kr/learn/courses/30/lessons/17676

# 입력 형식
solution 함수에 전달되는 lines 배열은 N(1 ≦ N ≦ 2,000)개의 로그 문자열로 되어 있으며, 각 로그 문자열마다 요청에 대한 응답완료시간 S와 처리시간 T가 공백으로 구분되어 있다.    
응답완료시간 S는 작년 추석인 2016년 9월 15일만 포함하여 고정 길이 2016-09-15 hh:mm:ss.sss 형식으로 되어 있다.   
처리시간 T는 0.1s, 0.312s, 2s 와 같이 최대 소수점 셋째 자리까지 기록하며 뒤에는 초 단위를 의미하는 s로 끝난다.   
예를 들어, 로그 문자열 2016-09-15 03:10:33.020 0.011s은 2016년 9월 15일 오전 3시 10분 **33.010초**부터 2016년 9월 15일 오전 3시 10분 **33.020초**까지 **0.011초** 동안 처리된 요청을 의미한다.    
(처리시간은 시작시간과 끝시간을 포함) 서버에는 타임아웃이 3초로 적용되어 있기 때문에 처리시간은 0.001 ≦ T ≦ 3.000이다.   
lines 배열은 응답완료시간 S를 기준으로 오름차순 정렬되어 있다.
# 출력 형식
solution 함수에서는 로그 데이터 lines 배열에 대해 초당 최대 처리량을 리턴한다.
# 입출력 예제
## 예제1
입력: [
2016-09-15 01:00:04.001 2.0s,
2016-09-15 01:00:07.000 2s
]

출력: 1

## 예제2
입력: [
2016-09-15 01:00:04.002 2.0s,
2016-09-15 01:00:07.000 2s
]

출력: 2

설명: 처리시간은 시작시간과 끝시간을 포함하므로
첫 번째 로그는 01:00:02.003 ~ 01:00:04.002에서 2초 동안 처리되었으며,
두 번째 로그는 01:00:05.001 ~ 01:00:07.000에서 2초 동안 처리된다.
따라서, 첫 번째 로그가 끝나는 시점과 두 번째 로그가 시작하는 시점의 구간인 01:00:04.002 ~ 01:00:05.001 1초 동안 최대 2개가 된다.

## 예제3
입력: [
2016-09-15 20:59:57.421 0.351s,
2016-09-15 20:59:58.233 1.181s,
2016-09-15 20:59:58.299 0.8s,
2016-09-15 20:59:58.688 1.041s,
2016-09-15 20:59:59.591 1.412s,
2016-09-15 21:00:00.464 1.466s,
2016-09-15 21:00:00.741 1.581s,
2016-09-15 21:00:00.748 2.31s,
2016-09-15 21:00:00.966 0.381s,
2016-09-15 21:00:02.066 2.62s
]

출력: 7

설명: 아래 타임라인 그림에서 빨간색으로 표시된 1초 각 구간의 처리량을 구해보면 (1)은 4개, (2)는 7개, (3)는 2개임을 알 수 있다.    
따라서 초당 최대 처리량은 7이 되며, 동일한 최대 처리량을 갖는 1초 구간은 여러 개 존재할 수 있으므로 이 문제에서는 구간이 아닌 개수만 출력한다.    

# 접근방법
이 문제는 딲 보자마자 앞으로 가야할 길이 백앤드 개발자라면 반드시 풀어야 할 문제다!!! 라 생각해서 풀어봤다.    
이 문제는 사실 알고리즘보다 입력된 시간들을 어떤 형태의 시간 데이터로 가공하고 처리할것인지가 더 중요한 것 같다.   

알고리즘은 간단하다. 출력값이 초당 최대 처리량이니 중요한 것은 __1초의 구간을 어떻게 잡을 것인가?__
1. 1000ms을 하나의 구간으로 잡고 처음부터 끝까지 비교해보기 -> 말이안됌   
2. 응답완료시간(T)을 포함한 +999ms의 구간만 확인하기   
쉽게 풀 수 있는 이유가 입력값이 정렬된 응답완료시간 리스트가 주어진다.이를 통해 (완료된 응답처리 순서대로 응답시작시간 리스트를 만들었다고 치자.)     
=> 그러면, 구간에는 해당 응답 처리보다 __앞서 완료된 처리는 고려할 필요 없을테고__    
=> 아직 완료되지않는 응답(S)에 대해서만 __응답 시작시간(S)이  T +999ms보다 작거나 같으면 응답(S)이 해당 구간(T)안에 포함된 것이므로__ 그떄만 count해준다.   

여기서 문제는 입력값을 어떻게 처리할것인가?
일단 from datetime import datetime, timedelta 한 이유는 datetime 모듈안에 datetime 타입이 있어 그냥 datetime 할경우 datetime.datetime 하면 오류가 뜬다.   
timedelta는 두 datetime의 차이 혹은 간격을 연산해줄 수 있는 datetime객체의 함수이다.(datetime의 연산을 하는데 도움을 주는 함수이다.)   

+ ['2016-09-15', '01:00:04.001', '2.0s']    
입력값이 주어지면 위처럼 공백기준으로 분류한 후 [0],[1]의 값을 합쳐서 하나의 datetime 객체로 [2]를 처리시간으로 분류한 뒤에 시작시작 객체를 계산해줬다.  


```python
from datetime import datetime, timedelta

def solution(lines):
    
    endTime = [] 
    startTime =[]
    for line in lines:
        temp = line.split(' ') # => ['2016-09-15', '01:00:04.001', '2.0s']
        time = str(temp[0]) + " " + str(temp[1]) # => 2016-09-15 01:00:04.001
    
         # 처리시간이 "2s"인 경우와 "2.0s"인 경우를 나누어서 처리.
        if '.' in temp[2]:
            delay = temp[2].split('.')
            delay[1] = delay[1][0:-1]
        else:
            delay = list(temp[2][0:-1])
            delay += ["0"]
        # => ['2', '0']
        end = datetime.fromisoformat(time)
        endTime.append(end)
        startTime.append(end - timedelta(seconds=int(delay[0]), milliseconds=int(delay[1]) - 1) ) 
        # 처리시간은 시작시간과 끝시간을 포함이므로 int(delay[1]) - 1을 더해주어야 함.
    answer =0
    #최대 응답 처리 개수
    index =0 
    # 응답시작시간 리스트의 index를 가리킴
    for i in endTime:
        count =1
        for j in range(index+1,len(startTime)):
            temp =i + timedelta(milliseconds =999 )
            #응답완료시간을 포함하여 1초이어야 하므로 999를 더해준다.
            if startTime[j] <=  temp :
                count+=1
        if count > answer :
            answer = count
        index+=1
    return answer

```

success~!

# 다른 방법

입력값 처리
- 초단위로 모두 환산하기
